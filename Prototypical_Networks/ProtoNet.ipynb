{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6b8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools as t\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5cf420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0573d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd079a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files_path = \"../ESC-10 Metadata/ESC10TestData.npy\"\n",
    "train_files_path = \"../ESC-10 Metadata/ESC10TrainData.npy\"\n",
    "test_labels_path = \"../ESC-10 Metadata/ESC10TestLabel.npy\"\n",
    "train_labels_path = \"../ESC-10 Metadata/ESC10TrainLabel.npy\"\n",
    "database_path = \"../ESC-10 Metadata/ESC10.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1310ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sounds, total_labels = t.get_dataset(test_files_path, train_files_path, test_labels_path, train_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7475f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class labels\n",
    "label_list = [\"baby cry\", \"chainsaw\", \"clock tick\", \"dogbark\", \"fire cracking\", \"helicopter\", \"sneezing\", \"rain\", \"rooster\", \"sea waves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8b91f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 7, 5, 4, 2, 3]) tensor(6) tensor([0, 9, 8])\n"
     ]
    }
   ],
   "source": [
    "# getting random train, test, validation classes from the whole meta dataset in 8:1:1 ratio\n",
    "classes = torch.randperm(10)\n",
    "train_classes, val_classes, test_classes = classes[:7], classes[0], classes[7:]\n",
    "print(train_classes, val_classes, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e14f3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = t.LoadData(total_sounds, total_labels, database_path, train_classes, transform = None)\n",
    "val_set = t.LoadData(total_sounds, total_labels, database_path, val_classes, transform = None)\n",
    "test_set = t.LoadData(total_sounds, total_labels, database_path, test_classes, transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6d3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sounds, train_labels = train_set.get_labels_n_sounds()\n",
    "val_sounds, val_labels = val_set.get_labels_n_sounds()\n",
    "test_sounds, test_labels = test_set.get_labels_n_sounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a04aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_way = 5\n",
    "k_shot = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9869bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = t.BatchSampler(n_way, k_shot, train_sounds, train_labels, include_query = True, shuffle = True)\n",
    "val_batches = t.BatchSampler(1, 3, val_sounds, val_labels, include_query = True, shuffle = True)\n",
    "test_batches = t.BatchSampler(1, 3, test_sounds, test_labels, include_query = True, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565f1a6",
   "metadata": {},
   "source": [
    "Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e13ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0044d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protonet_conv(**kwargs):\n",
    "    x_dim = kwargs['x_dim']\n",
    "    hid_dim = kwargs['hid_dim']\n",
    "    z_dim = kwargs['z_dim']\n",
    "    \n",
    "    def conv_block(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "    encoder = nn.Sequential(\n",
    "    conv_block(x_dim, hid_dim),\n",
    "    conv_block(hid_dim, hid_dim),\n",
    "    conv_block(hid_dim, hid_dim),\n",
    "#     conv_block(hid_dim, hid_dim),\n",
    "    conv_block(hid_dim, z_dim),\n",
    "    Flatten()\n",
    "    )\n",
    "    \n",
    "    return ProtoNet(encoder)\n",
    "#     return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b9aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "    \n",
    "    return torch.pow(x - y, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "652c6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = encoder.cuda()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def set_forward_loss(self, batch_indices):\n",
    "        batch_imgs = []\n",
    "        for ind in batch_indices:\n",
    "            batch_imgs.append(train_sounds[ind])\n",
    "        \n",
    "        support_sounds, query_sounds, support_targets, query_targets = t.split_batch(batch_imgs, batch_indices, n_way, k_shot)\n",
    "        support_sg, query_sg = [], []\n",
    "        f = h5py.File(database_path, 'r')\n",
    "        \n",
    "        for sd in support_sounds:\n",
    "            sg = f[sd][()]\n",
    "            sg = np.float32(sg)\n",
    "            support_sg.append(np.array(sg))\n",
    "        for sd in query_sounds:\n",
    "            sg = f[sd][()]\n",
    "            sg = np.float32(sg)\n",
    "            query_sg.append(np.array(sg))\n",
    "        support_sg, query_sg = np.array(support_sg), np.array(query_sg)\n",
    "            \n",
    "        iss = support_sg.shape\n",
    "        support_sg = np.reshape(support_sg, (iss[0], 1, iss[1], iss[2]))\n",
    "        iss = query_sg.shape\n",
    "        query_sg = np.reshape(query_sg, (iss[0], 1, iss[1], iss[2]))\n",
    "        support_protos = {}\n",
    "        \n",
    "        support_sg = torch.tensor(np.float32(support_sg)).to(\"cuda\")\n",
    "        query_sg = torch.tensor(np.float32(query_sg)).to(\"cuda\")\n",
    "        support_feats = self.encoder(support_sg)\n",
    "        query_feats = self.encoder(query_sg)\n",
    "        \n",
    "        target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, k_shot, 1).long()\n",
    "        target_inds = Variable(target_inds, requires_grad=False)\n",
    "        target_inds = target_inds.cuda()\n",
    "        \n",
    "        for i in range(0, support_feats.shape[0], k_shot):\n",
    "            support_protos[train_labels[support_targets[i]]] = support_feats[i: i + k_shot].mean(dim = 0)\n",
    "\n",
    "        support_protos_tensor = torch.stack([p for p in support_protos.values()], dim = 0)\n",
    "        dists = euclidean_dist(query_feats, support_protos_tensor)\n",
    "        \n",
    "        log_p_y = F.log_softmax(-dists, dim=1).view(n_way, k_shot, -1)\n",
    "#         log_p_y.max(1).indices.requires_grad = True\n",
    "#         int_targs = torch.tensor([int(i) for i in target_inds])\n",
    "        \n",
    "        loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "        _, y_hat = log_p_y.max(2)\n",
    "        acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n",
    "        \n",
    "        return loss_val, {\"loss\": loss_val.item(), \"acc\": acc_val.item(), \"y_hat\": y_hat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0445e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tnrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5522571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, n_way, k_shot, train_sounds, train_labels, max_epoch, epoch_size):\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n",
    "    epoch = 0 #epochs done so far\n",
    "    stop = False #status to know when to stop\n",
    "\n",
    "    while epoch < max_epoch and not stop:\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        \n",
    "        for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n",
    "            train_batches = t.BatchSampler(n_way, k_shot, train_sounds, train_labels, include_query = True, shuffle = True)\n",
    "            tb = iter(train_batches)\n",
    "            sample = next(tb)\n",
    "            optimizer.zero_grad()\n",
    "            loss, output = model.set_forward_loss(sample)\n",
    "            running_loss += output['loss']\n",
    "            running_acc += output['acc']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = running_loss / epoch_size\n",
    "        epoch_acc = running_acc / epoch_size\n",
    "        print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n",
    "        epoch += 1\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c628de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_protonet_conv(\n",
    "    x_dim=1,\n",
    "    hid_dim=64,\n",
    "    z_dim=64,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8eaf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Sharma\\AppData\\Local\\Temp\\ipykernel_33672\\4100829836.py:10: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9eefa1b84c34e1394392d1b745a06ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Loss: 8.6777 Acc: 0.9251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6a4f428bf94c6ea667f4147857ca3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -- Loss: 0.1455 Acc: 0.9615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b4b0d39ab64c48b15e2469253647a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -- Loss: 0.0767 Acc: 0.9771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e9ccfb8a8f46b48c84fb735ccf043f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -- Loss: 0.0476 Acc: 0.9848\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "n_way = 5\n",
    "k_shot = 5\n",
    "\n",
    "max_epoch = 4\n",
    "epoch_size = 2000\n",
    "\n",
    "train(model, optimizer, n_way, k_shot, train_sounds, train_labels, max_epoch, epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "383d08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"way5shot1_fullspec_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adef789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimizer, n_way, k_shot, test_sounds, test_labels, test_episode):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for episode in tnrange(test_episode):\n",
    "        test_batches = t.BatchSampler(n_way, k_shot, test_sounds, test_labels, include_query = True, shuffle = True)\n",
    "        tb = iter(test_batches)\n",
    "        sample = next(tb)\n",
    "        \n",
    "        loss, output = model.set_forward_loss(sample)\n",
    "        running_loss += output['loss']\n",
    "        running_acc += output['acc']\n",
    "    avg_loss = running_loss / test_episode\n",
    "    avg_acc = running_acc / test_episode\n",
    "    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05e5f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "071fb378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Sharma\\AppData\\Local\\Temp\\ipykernel_33672\\1064312205.py:9: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for episode in tnrange(test_episode):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2a75e1677b4c12931d6c478f846272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results -- Loss: 4.3240 Acc: 0.6000\n"
     ]
    }
   ],
   "source": [
    "n_way = 3\n",
    "k_shot = 5\n",
    "\n",
    "test_episode = 200\n",
    "\n",
    "# model.load_state_dict(torch.load(\"way5shot5_fullspec_model1\"))\n",
    "test(model, optimizer, n_way, k_shot, test_sounds, test_labels, test_episode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
